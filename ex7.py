import json
import timeit
import sys
import matplotlib.pyplot as plt

sys.setrecursionlimit(20000)

def binarysearch(data, first, last, mid, key):
    if first <= last:
        if key == data[mid]:
            return mid
        elif key < data[mid]:
            return binarysearch(data, first, mid-1, (first+mid-1)//2, key)
        elif key > data[mid]:
            return binarysearch(data, mid+1, last, (mid+1+last)//2, key)
    return -1


def midsearch(data, tasks, mid):
    results = []
    for task in tasks:
        execution_time = timeit.timeit(lambda: binarysearch(data, 0, len(data)-1, mid, task), number=100)
        avg_time = execution_time / 100
        results.append((task, avg_time))
    return results

with open("ex7data.json", 'r', encoding="utf-8") as inF:
    data = json.load(inF)
with open("ex7tasks.json",'r', encoding="utf-8") as inT:
    tasks = json.load(inT)


midpoints = [0, 10000, 50000, 150000, 250000, 350000, 450000, 550000, 650000, 750000, len(data) -1]

best_midpoints = {}
for midpoint in midpoints:
    results = midsearch(data, tasks, midpoint)
    for task, execution_time in results:
#Lines for rest of the function generated by ChatGPT
        if task not in best_midpoints or best_midpoints[task][1] > execution_time:
            best_midpoints[task] = (midpoint, execution_time)
tasks = [task for task in best_midpoints.keys()]
midpoints = [best_midpoints[task][0] for task in tasks]

tasks = [task for task in best_midpoints.keys()]
midpoints = [best_midpoints[task][0] for task in tasks]

#Line below from ChatGPT
tasks, midpoints = zip(*sorted(zip(tasks, midpoints)))


plt.figure(figsize=(20, 10))
plt.scatter(tasks, midpoints)  
plt.xlabel('Tasks')
plt.ylabel('Best Chosen Midpoints')
plt.title('Scatterplot of Tasks and Corresponding Chosen Midpoints')
plt.show()

#4. From the graph we can see some patterns, like the most concentrated areas for the tasks having a higher midpoint as have a higher value for the task. 
# This follows the assumption that the closer to the midpoint the value is, the faster it will be. 
# Despite this, there is still a large amount of random in the data which is due to the way binary search works. Since the search splits in half after chosing the midpoint,
# if the value we are searching for is in the start or end of the initally split arrays, it will end up taking longer. 
# We can conclude there is a very slight linear corellation between the chosen midpoint and the performance, with the performance being faster if it is closer to the key value,
# however, there is a lot of variance in this algorithm that makes it hard to predict. 